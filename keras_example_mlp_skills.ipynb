{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only use the first GPU\n",
    "#   try:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Visible devices must be set before GPUs have been initialized\n",
    "#     print(e)\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们将以mlp对为，基础模型，然后介绍一些深度学习常见技巧， 如：\n",
    "# 权重初始化， 激活函数， 优化器， 批规范化， dropout，模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)   (60000,)\n",
      "(10000, 784)   (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape([x_train.shape[0], -1])\n",
    "x_test = x_test.reshape([x_test.shape[0], -1])\n",
    "print(x_train.shape, ' ', y_train.shape)\n",
    "print(x_test.shape, ' ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 06:07:40.509709 140563961509632 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/100\n",
      "42000/42000 [==============================] - 2s 47us/sample - loss: 8.2464 - accuracy: 0.4807 - val_loss: 7.1473 - val_accuracy: 0.5509\n",
      "Epoch 2/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 5.8212 - accuracy: 0.6318 - val_loss: 5.4804 - val_accuracy: 0.6540\n",
      "Epoch 3/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 3.7419 - accuracy: 0.7581 - val_loss: 2.6328 - val_accuracy: 0.8276\n",
      "Epoch 4/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.5026 - accuracy: 0.8372 - val_loss: 2.4999 - val_accuracy: 0.8368\n",
      "Epoch 5/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.3123 - accuracy: 0.8500 - val_loss: 2.4904 - val_accuracy: 0.8381\n",
      "Epoch 6/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.2630 - accuracy: 0.8531 - val_loss: 2.3505 - val_accuracy: 0.8476\n",
      "Epoch 7/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.1712 - accuracy: 0.8595 - val_loss: 2.2760 - val_accuracy: 0.8526\n",
      "Epoch 8/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.1289 - accuracy: 0.8622 - val_loss: 2.2984 - val_accuracy: 0.8515\n",
      "Epoch 9/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 2.1040 - accuracy: 0.8636 - val_loss: 2.2112 - val_accuracy: 0.8571\n",
      "Epoch 10/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.0450 - accuracy: 0.8680 - val_loss: 2.1436 - val_accuracy: 0.8607\n",
      "Epoch 11/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 1.9816 - accuracy: 0.8720 - val_loss: 2.1303 - val_accuracy: 0.8627\n",
      "Epoch 12/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 1.9804 - accuracy: 0.8719 - val_loss: 2.1857 - val_accuracy: 0.8586\n",
      "Epoch 13/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 2.0029 - accuracy: 0.8702 - val_loss: 2.1300 - val_accuracy: 0.8622\n",
      "Epoch 14/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 1.9670 - accuracy: 0.8732 - val_loss: 2.1606 - val_accuracy: 0.8606\n",
      "Epoch 15/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 1.6890 - accuracy: 0.8870 - val_loss: 0.9084 - val_accuracy: 0.9315\n",
      "Epoch 16/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6349 - accuracy: 0.9517 - val_loss: 0.8374 - val_accuracy: 0.9372\n",
      "Epoch 17/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.7402 - accuracy: 0.9456 - val_loss: 0.7163 - val_accuracy: 0.9466\n",
      "Epoch 18/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5004 - accuracy: 0.9625 - val_loss: 0.7076 - val_accuracy: 0.9478\n",
      "Epoch 19/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.4551 - accuracy: 0.9654 - val_loss: 0.6060 - val_accuracy: 0.9549\n",
      "Epoch 20/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4016 - accuracy: 0.9686 - val_loss: 0.5945 - val_accuracy: 0.9549\n",
      "Epoch 21/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3779 - accuracy: 0.9703 - val_loss: 0.5523 - val_accuracy: 0.9578\n",
      "Epoch 22/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3362 - accuracy: 0.9736 - val_loss: 0.5419 - val_accuracy: 0.9573\n",
      "Epoch 23/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.3433 - accuracy: 0.9723 - val_loss: 0.5306 - val_accuracy: 0.9593\n",
      "Epoch 24/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3120 - accuracy: 0.9747 - val_loss: 0.6106 - val_accuracy: 0.9537\n",
      "Epoch 25/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2801 - accuracy: 0.9770 - val_loss: 0.5396 - val_accuracy: 0.9582\n",
      "Epoch 26/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2655 - accuracy: 0.9786 - val_loss: 0.5018 - val_accuracy: 0.9607\n",
      "Epoch 27/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2595 - accuracy: 0.9785 - val_loss: 0.5266 - val_accuracy: 0.9589\n",
      "Epoch 28/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2426 - accuracy: 0.9803 - val_loss: 0.5158 - val_accuracy: 0.9603\n",
      "Epoch 29/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2929 - accuracy: 0.9756 - val_loss: 0.4769 - val_accuracy: 0.9606\n",
      "Epoch 30/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2322 - accuracy: 0.9801 - val_loss: 0.4889 - val_accuracy: 0.9617\n",
      "Epoch 31/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2451 - accuracy: 0.9790 - val_loss: 0.4725 - val_accuracy: 0.9623\n",
      "Epoch 32/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2211 - accuracy: 0.9807 - val_loss: 0.4798 - val_accuracy: 0.9625\n",
      "Epoch 33/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2090 - accuracy: 0.9821 - val_loss: 0.4657 - val_accuracy: 0.9629\n",
      "Epoch 34/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.2036 - accuracy: 0.9821 - val_loss: 0.4781 - val_accuracy: 0.9609\n",
      "Epoch 35/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1949 - accuracy: 0.9824 - val_loss: 0.4612 - val_accuracy: 0.9627\n",
      "Epoch 36/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1817 - accuracy: 0.9839 - val_loss: 0.5079 - val_accuracy: 0.9589\n",
      "Epoch 37/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1795 - accuracy: 0.9842 - val_loss: 0.4670 - val_accuracy: 0.9619\n",
      "Epoch 38/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1743 - accuracy: 0.9836 - val_loss: 0.4737 - val_accuracy: 0.9604\n",
      "Epoch 39/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1542 - accuracy: 0.9865 - val_loss: 0.4380 - val_accuracy: 0.9626\n",
      "Epoch 40/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.1420 - accuracy: 0.9870 - val_loss: 0.4383 - val_accuracy: 0.9627\n",
      "Epoch 41/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1445 - accuracy: 0.9870 - val_loss: 0.4148 - val_accuracy: 0.9638\n",
      "Epoch 42/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1830 - accuracy: 0.9824 - val_loss: 0.4488 - val_accuracy: 0.9622\n",
      "Epoch 43/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1528 - accuracy: 0.9862 - val_loss: 0.4199 - val_accuracy: 0.9635\n",
      "Epoch 44/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1565 - accuracy: 0.9854 - val_loss: 0.4431 - val_accuracy: 0.9623\n",
      "Epoch 45/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1381 - accuracy: 0.9869 - val_loss: 0.4415 - val_accuracy: 0.9639\n",
      "Epoch 46/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.1277 - accuracy: 0.9879 - val_loss: 0.4321 - val_accuracy: 0.9626\n",
      "Epoch 47/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1379 - accuracy: 0.9870 - val_loss: 0.4333 - val_accuracy: 0.9622\n",
      "Epoch 48/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1346 - accuracy: 0.9870 - val_loss: 0.4368 - val_accuracy: 0.9621\n",
      "Epoch 49/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1235 - accuracy: 0.9878 - val_loss: 0.4062 - val_accuracy: 0.9632\n",
      "Epoch 50/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1244 - accuracy: 0.9874 - val_loss: 0.3994 - val_accuracy: 0.9640\n",
      "Epoch 51/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1199 - accuracy: 0.9883 - val_loss: 0.3895 - val_accuracy: 0.9647\n",
      "Epoch 52/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.1111 - accuracy: 0.9886 - val_loss: 0.3781 - val_accuracy: 0.9647\n",
      "Epoch 53/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1454 - accuracy: 0.9844 - val_loss: 0.4071 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.1089 - accuracy: 0.9885 - val_loss: 0.3956 - val_accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.1059 - accuracy: 0.9894 - val_loss: 0.4226 - val_accuracy: 0.9602\n",
      "Epoch 56/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.1051 - accuracy: 0.9889 - val_loss: 0.4064 - val_accuracy: 0.9626\n",
      "Epoch 57/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0852 - accuracy: 0.9911 - val_loss: 0.4173 - val_accuracy: 0.9632\n",
      "Epoch 58/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1011 - accuracy: 0.9892 - val_loss: 0.4092 - val_accuracy: 0.9639\n",
      "Epoch 59/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0855 - accuracy: 0.9907 - val_loss: 0.4023 - val_accuracy: 0.9632\n",
      "Epoch 60/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0760 - accuracy: 0.9922 - val_loss: 0.3809 - val_accuracy: 0.9654\n",
      "Epoch 61/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0760 - accuracy: 0.9920 - val_loss: 0.3663 - val_accuracy: 0.9652\n",
      "Epoch 62/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0754 - accuracy: 0.9922 - val_loss: 0.3883 - val_accuracy: 0.9651\n",
      "Epoch 63/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0744 - accuracy: 0.9921 - val_loss: 0.3901 - val_accuracy: 0.9641\n",
      "Epoch 64/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0816 - accuracy: 0.9909 - val_loss: 0.3864 - val_accuracy: 0.9639\n",
      "Epoch 65/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0855 - accuracy: 0.9902 - val_loss: 0.3890 - val_accuracy: 0.9634\n",
      "Epoch 66/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0777 - accuracy: 0.9911 - val_loss: 0.3672 - val_accuracy: 0.9640\n",
      "Epoch 67/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0844 - accuracy: 0.9907 - val_loss: 0.3905 - val_accuracy: 0.9638\n",
      "Epoch 68/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0807 - accuracy: 0.9907 - val_loss: 0.3940 - val_accuracy: 0.9621\n",
      "Epoch 69/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.0839 - accuracy: 0.9907 - val_loss: 0.3664 - val_accuracy: 0.9643\n",
      "Epoch 70/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0775 - accuracy: 0.9910 - val_loss: 0.3689 - val_accuracy: 0.9642\n",
      "Epoch 71/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0686 - accuracy: 0.9921 - val_loss: 0.3976 - val_accuracy: 0.9621\n",
      "Epoch 72/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0735 - accuracy: 0.9915 - val_loss: 0.3668 - val_accuracy: 0.9647\n",
      "Epoch 73/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0776 - accuracy: 0.9908 - val_loss: 0.3687 - val_accuracy: 0.9649\n",
      "Epoch 74/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0718 - accuracy: 0.9907 - val_loss: 0.3540 - val_accuracy: 0.9636\n",
      "Epoch 75/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0676 - accuracy: 0.9916 - val_loss: 0.3260 - val_accuracy: 0.9678\n",
      "Epoch 76/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0524 - accuracy: 0.9945 - val_loss: 0.3363 - val_accuracy: 0.9668\n",
      "Epoch 77/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0490 - accuracy: 0.9950 - val_loss: 0.3281 - val_accuracy: 0.9669\n",
      "Epoch 78/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0437 - accuracy: 0.9952 - val_loss: 0.3081 - val_accuracy: 0.9684\n",
      "Epoch 79/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0449 - accuracy: 0.9953 - val_loss: 0.3503 - val_accuracy: 0.9652\n",
      "Epoch 80/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0512 - accuracy: 0.9936 - val_loss: 0.3454 - val_accuracy: 0.9661\n",
      "Epoch 81/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0780 - accuracy: 0.9900 - val_loss: 0.3686 - val_accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0528 - accuracy: 0.9937 - val_loss: 0.3552 - val_accuracy: 0.9648\n",
      "Epoch 83/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0564 - accuracy: 0.9930 - val_loss: 0.3257 - val_accuracy: 0.9666\n",
      "Epoch 84/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0520 - accuracy: 0.9931 - val_loss: 0.3534 - val_accuracy: 0.9634\n",
      "Epoch 85/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0800 - accuracy: 0.9893 - val_loss: 0.3510 - val_accuracy: 0.9610\n",
      "Epoch 86/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.0536 - accuracy: 0.9924 - val_loss: 0.3373 - val_accuracy: 0.9657\n",
      "Epoch 87/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0515 - accuracy: 0.9933 - val_loss: 0.3289 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0462 - accuracy: 0.9940 - val_loss: 0.3530 - val_accuracy: 0.9639\n",
      "Epoch 89/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0476 - accuracy: 0.9946 - val_loss: 0.3141 - val_accuracy: 0.9669\n",
      "Epoch 90/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0500 - accuracy: 0.9930 - val_loss: 0.3153 - val_accuracy: 0.9662\n",
      "Epoch 91/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0524 - accuracy: 0.9932 - val_loss: 0.3230 - val_accuracy: 0.9659\n",
      "Epoch 92/100\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.0598 - accuracy: 0.9916 - val_loss: 0.3340 - val_accuracy: 0.9646\n",
      "Epoch 93/100\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.0436 - accuracy: 0.9945 - val_loss: 0.3382 - val_accuracy: 0.9656\n",
      "Epoch 94/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0424 - accuracy: 0.9951 - val_loss: 0.3152 - val_accuracy: 0.9655\n",
      "Epoch 95/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0330 - accuracy: 0.9965 - val_loss: 0.3219 - val_accuracy: 0.9676\n",
      "Epoch 96/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0409 - accuracy: 0.9944 - val_loss: 0.3289 - val_accuracy: 0.9659\n",
      "Epoch 97/100\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.0330 - accuracy: 0.9960 - val_loss: 0.3395 - val_accuracy: 0.9658\n",
      "Epoch 98/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0382 - accuracy: 0.9948 - val_loss: 0.3450 - val_accuracy: 0.9649\n",
      "Epoch 99/100\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.0489 - accuracy: 0.9931 - val_loss: 0.3163 - val_accuracy: 0.9671\n",
      "Epoch 100/100\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 0.0357 - accuracy: 0.9953 - val_loss: 0.3280 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#要运行两次才显示图像，不知为什么\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 86us/sample - loss: 0.2717 - accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.权重初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=256, epochs=100, validation_split=0.3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
